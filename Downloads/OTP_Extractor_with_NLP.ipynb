{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRP_OH-WKgoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7aa9be-e2eb-42ef-f596-a46f6d255a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digit Chunks: []\n",
            "TF-IDF Matrix:\n",
            " [[0.33264172 0.         0.         0.         0.33264172 0.33264172\n",
            "  0.33264172 0.         0.         0.33264172 0.23667732 0.\n",
            "  0.23667732 0.33264172 0.47335464]\n",
            " [0.         0.36469323 0.36469323 0.36469323 0.         0.\n",
            "  0.         0.36469323 0.36469323 0.         0.25948224 0.36469323\n",
            "  0.25948224 0.         0.25948224]]\n",
            "Feature Names: ['123456' '987654' 'code' 'complete' 'is' 'login' 'otp' 'please' 'the'\n",
            " 'this' 'to' 'transaction' 'use' 'verify' 'your']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import psycopg2\n",
        "import argparse\n",
        "import json\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "DATABASE_CONFIG = {\n",
        "    'dbname': 'sms_firewall',\n",
        "    'user': 'postgres',\n",
        "    'password': 'postgres',\n",
        "    'host': 'localhost',\n",
        "    'port': '5432'\n",
        "}\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "otp_type_sms_keywords = {\n",
        "    \"code\": 2, \"pin\": 2, \"otp\": 3, \"otp is:\": 3, \"otp is :\": 3, \"otp is -\": 3, \"otp is-\": 3, \"code is:\": 3,\n",
        "    \"code is :\": 3, \"code is -\": 3, \"code is-\": 3, \"login otp\": 2, \"verification\": 1, \"authentication\": 1,\n",
        "    \"credential\": 1, \"password\": 2, \"reference\": 1, \"number\": 1, \"vrn\": 1, \"login\": 1, \"confirmation\": 1,\n",
        "    \"secret\": 1, \"security code\": 2, \"auth code\": 2, \"কোড\": 2, \"পিন\": 2, \"ওটিপি\": 3, \"লগইন ওটিপি\": 2,\n",
        "    \"যাচাইকরণ\": 1, \"প্রমাণীকরণ\": 1, \"শংসাপত্র\": 1, \"পাসওয়ার্ড\": 2, \"রেফারেন্স\": 1, \"নম্বর\": 1,\n",
        "    \"ভিআরএন\": 1, \"লগইন\": 1, \"নিশ্চিতকরণ\": 1, \"নতুন পাসওয়ার্ড\": 1, \"গোপন\": 1\n",
        "}\n",
        "\n",
        "def retrieve_url(text):\n",
        "    pattern = r'(?:[A-Za-z0-9\\-]+\\.[A-Za-z]{2,}|' \\\n",
        "              r'(?:http|ftp)s?://' \\\n",
        "              r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' \\\n",
        "              r'localhost|' \\\n",
        "              r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}|' \\\n",
        "              r'\\[?[A-F0-9]*:[A-F0-9:]+\\]?)' \\\n",
        "              r'(?::\\d+)?' \\\n",
        "              r'(?:/?|[/?]\\S+))'\n",
        "\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "    if match:\n",
        "        if re.search(r'\\.\\w{2,3}$', match.group()):\n",
        "            return match.group()\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def remove_urls(text):\n",
        "    detected_url = retrieve_url(text)\n",
        "    if detected_url:\n",
        "        text = re.sub(re.escape(detected_url), '', text)\n",
        "    return text\n",
        "\n",
        "def score_sentences(text):\n",
        "    doc = nlp(text)\n",
        "    sentences = list(doc.sents)\n",
        "    sentence_scores = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_text = sentence.text.lower()\n",
        "        score = sum(otp_type_sms_keywords.get(keyword, 0) for keyword in otp_type_sms_keywords if keyword in sentence_text)\n",
        "        if score > 0:\n",
        "            sentence_scores.append((score, sentence_text))\n",
        "\n",
        "    if not sentence_scores:\n",
        "        print(\"It doesn't seem like an OTP SMS.\")\n",
        "        return None\n",
        "\n",
        "    best_sentence = max(sentence_scores, key=lambda x: x[0])[1]\n",
        "    return best_sentence\n",
        "\n",
        "def find_closest_chunk(digit_chunks, best_sentence):\n",
        "    keyword_positions = {}\n",
        "    for keyword, weight in otp_type_sms_keywords.items():\n",
        "        if keyword.lower() in best_sentence:\n",
        "            keyword_positions[keyword.lower()] = best_sentence.find(keyword.lower())\n",
        "\n",
        "    closest_chunk = None\n",
        "    min_weighted_distance = float('inf')\n",
        "\n",
        "    for chunk in digit_chunks:\n",
        "        chunk_position = best_sentence.find(chunk)\n",
        "        for keyword, position in keyword_positions.items():\n",
        "            distance = abs(chunk_position - position)\n",
        "            weighted_distance = distance / otp_type_sms_keywords[keyword]\n",
        "            if weighted_distance < min_weighted_distance:\n",
        "                min_weighted_distance = weighted_distance\n",
        "                closest_chunk = chunk\n",
        "\n",
        "    return closest_chunk\n",
        "\n",
        "def extract_otp(text):\n",
        "    text = remove_urls(text)\n",
        "    best_sentence = score_sentences(text)\n",
        "\n",
        "    if not best_sentence:\n",
        "        return None\n",
        "\n",
        "    digit_chunks = re.findall(r'\\b\\w*[\\w@-]*\\d{4,}\\b', best_sentence)\n",
        "\n",
        "    if len(digit_chunks) == 1:\n",
        "        return digit_chunks[0]\n",
        "\n",
        "    closest_chunk = find_closest_chunk(digit_chunks, best_sentence)\n",
        "    print(\"Closest Chunk:\", closest_chunk)\n",
        "    return closest_chunk\n",
        "\n",
        "def init_db():\n",
        "    conn = psycopg2.connect(**DATABASE_CONFIG)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''CREATE TABLE IF NOT EXISTS rules (\n",
        "                        id SERIAL PRIMARY KEY,\n",
        "                        sms_type TEXT NOT NULL,\n",
        "                        rule_type TEXT NOT NULL CHECK(rule_type IN ('block', 'pass')),\n",
        "                        regex_pattern TEXT NOT NULL,\n",
        "                        status BOOLEAN NOT NULL)''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def regex_length(length, comparison='greater'):\n",
        "    if comparison == 'greater':\n",
        "        pattern = r'^\\d{' + str(length + 1) + r',}$'\n",
        "    elif comparison == 'less':\n",
        "        pattern = r'^\\d{1,' + str(length - 1) + r'}$'\n",
        "    elif comparison == 'equals':\n",
        "        pattern = r'^\\d{' + str(length) + r'}$'\n",
        "    else:\n",
        "        raise ValueError(\"Invalid comparison. Use 'greater', 'less', or 'equal'.\")\n",
        "    return pattern\n",
        "\n",
        "def regex_sequence(sequence, comparison='starts with'):\n",
        "    escaped_sequence = re.escape(sequence)\n",
        "    if comparison == 'starts with':\n",
        "        pattern = r'^' + escaped_sequence\n",
        "    elif comparison == 'ends with':\n",
        "        pattern = escaped_sequence + r'$'\n",
        "    elif comparison == 'contains':\n",
        "        pattern = r'.*' + escaped_sequence + r'.*'\n",
        "    else:\n",
        "        raise ValueError(\"Invalid comparison. Use 'starts with', 'ends with', 'contains'.\")\n",
        "    return pattern\n",
        "\n",
        "def generate_regex(sms_type, category, features):\n",
        "    features = json.loads(features)\n",
        "    if sms_type == 'OTP':\n",
        "        if category == 'length':\n",
        "            pattern = regex_length(features['length'], features.get('comparison', 'greater'))\n",
        "        elif category == 'sequence':\n",
        "            pattern = regex_sequence(features['sequence'], features.get('comparison', 'starts with'))\n",
        "        else:\n",
        "            raise ValueError(\"Invalid category. Use 'length' or 'sequence'.\")\n",
        "    else:\n",
        "        raise ValueError(\"Invalid sms_type. Only 'OTP' is supported.\")\n",
        "    return pattern\n",
        "\n",
        "def add_rule(sms_type, rule_type, category, features, status=True):\n",
        "    regex_pattern = generate_regex(sms_type, category, features)\n",
        "    conn = psycopg2.connect(**DATABASE_CONFIG)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    try:\n",
        "        cursor.execute('''\n",
        "            SELECT regex_pattern FROM rules\n",
        "            WHERE sms_type = %s AND rule_type = %s\n",
        "        ''', (sms_type, rule_type))\n",
        "        existing_patterns = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "        if regex_pattern not in existing_patterns:\n",
        "            cursor.execute('''\n",
        "                INSERT INTO rules (sms_type, rule_type, regex_pattern, status)\n",
        "                VALUES (%s, %s, %s, %s)\n",
        "            ''', (sms_type, rule_type, regex_pattern, status))\n",
        "            print(f\"Added new rule: {rule_type} - {regex_pattern} with status {status}\")\n",
        "        else:\n",
        "            print(f\"Pattern already exists: {regex_pattern}\")\n",
        "\n",
        "        conn.commit()\n",
        "    except psycopg2.Error as e:\n",
        "        print(f\"Database error: {e}\")\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "def get_rules(sms_type):\n",
        "    conn = psycopg2.connect(**DATABASE_CONFIG)\n",
        "    cursor = conn.cursor()\n",
        "    query = '''\n",
        "        SELECT rule_type, regex_pattern\n",
        "        FROM rules\n",
        "        WHERE sms_type = %s AND status = TRUE\n",
        "    '''\n",
        "    cursor.execute(query, (sms_type,))\n",
        "    rules = cursor.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    block_rules = []\n",
        "    pass_rules = []\n",
        "\n",
        "    for rule in rules:\n",
        "        rule_type, regex_pattern = rule\n",
        "        if rule_type == 'block':\n",
        "            block_rules.append(regex_pattern)\n",
        "        elif rule_type == 'pass':\n",
        "            pass_rules.append(regex_pattern)\n",
        "        else:\n",
        "            print(\"No rule_type matched\")\n",
        "    return block_rules, pass_rules\n",
        "\n",
        "def tfidf_vectorizer(sentences):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "    return tfidf_matrix, vectorizer\n",
        "\n",
        "def nlp_based_regex_generation(texts):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    digit_chunks = []\n",
        "    for text in texts:\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"CARDINAL\":\n",
        "                digit_chunks.append(ent.text)\n",
        "    return digit_chunks\n",
        "\n",
        "# Example Usage\n",
        "texts = [\n",
        "    \"Your OTP is 123456. Use this to verify your login.\",\n",
        "    \"Please use the code 987654 to complete your transaction.\"\n",
        "]\n",
        "\n",
        "digit_chunks = nlp_based_regex_generation(texts)\n",
        "tfidf_matrix, vectorizer = tfidf_vectorizer(texts)\n",
        "print(\"Digit Chunks:\", digit_chunks)\n",
        "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())\n",
        "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2S8U1oKH973"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}